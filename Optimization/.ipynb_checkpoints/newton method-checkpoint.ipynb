{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超定方程组 \n",
    "对于方程组Ra=y，R为n×m矩阵，如果R列满秩，且n>m。则方程组没有精确解，此时称方程组为超定方程组。   \n",
    "1. 超定方程一般是不存在解的矛盾方程，比较常用的方法是最小二乘法。  \n",
    "2. 曲线拟合是最小二乘法要解决的问题，实际上就是求以上超定方程组的最小二乘解的问题。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "m = 100\n",
    "np.random.seed(5)\n",
    "x = np.random.normal(0, 1, m * n).reshape(m, n)\n",
    "np.random.seed(10)\n",
    "y = np.dot(x, np.array(range(1, n + 1))) + np.random.normal(0, 0.1, m)\n",
    "\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乘法 \n",
    "假设数据集有m行n列，且满足m > n，那么这个方程组有m个方程和n个未知数，无法求解   \n",
    "\n",
    "由于：  \n",
    "$e_{i} = Y_{i} - \\hat{Y_{i}}$  \n",
    "\n",
    "$e_{i} = Y_{i} - (\\sum_{j=1}^{n}\\beta_{j}X_{ij})$  \n",
    "\n",
    "$MSE = \\frac{1}{m}\\sum_{i=1}^{m}e_{i}^2 = \\frac{1}{m}\\sum_{1}^{m}(Y_{i} - \\sum_{j=1}^{n}\\beta_{j}X_{ij})^2$  \n",
    "\n",
    "显然我们不太可能找到一组解让MSE等于0，但是我们可以求出一组解让MSE最小。  上面关于MSE的等式称作损失函数，我们求解方程组的任务也转为最小化损失函数的值。对n个beta求偏导，令偏导数等于零，则得到n个方程组且有n个未知数，方程组有唯一解如下：\n",
    "\n",
    "$\\beta = (X^TX)^{-1}X^TY$\n",
    "\n",
    "通过numpy的矩阵乘法、求逆和转置来实现least_squares_method，并与numpy自带的线性最小二乘求解函数np.linalg.lstsq进行结果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(x):\n",
    "    return np.concatenate((np.ones(x.shape[0]).reshape(-1,1), x), axis=1)\n",
    "\n",
    "\n",
    "t = np.array(range(10)).reshape(5, 2)\n",
    "print(\"The origin x is:\\n\", t, '\\n')\n",
    "\n",
    "t = add_bias(t)\n",
    "print(\"The result is:\\n\", t, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_method(x, y):\n",
    "    x = np.mat(add_bias(x))\n",
    "    y = np.mat(y).T\n",
    "    return np.array((x.T * x).I * x.T * y)\n",
    "\n",
    "betas1 = least_squares_method(x, y)\n",
    "betas2 = np.linalg.lstsq(add_bias(x), y)[0].reshape(-1, 1)\n",
    "print(np.concatenate((betas1, betas2), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  什么是牛顿法\n",
    "牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f(x)的泰勒级数的前面几项来寻找方程f(y)=0的根。  \n",
    "  \n",
    "泰勒公式，如果$f(x)$在点$x=x_0$具有任意阶导数，则幂级数  \n",
    "$f(x) = \\large\\frac{f(x_0)}{0!}\\normalsize+\\large\\frac{f'(x_0)}{1!} \\normalsize(x-x_0)+\\large\\frac{f''(x_0)}{2!} \\normalsize(x-x_0)^2\n",
    "+...+\\large\\frac{f^{(n)}(x_0)}{n!} \\normalsize(x-x_0)^n + R_n(x)$  \n",
    "x_0是初始值，x_1是x_0更新后的值  \n",
    "近似认为：$f(x_1) = f(x_0) + (x_1 - x_0)f'(x_0) +(x_1 - x_0)^2\\large\\frac{f''(x_0)}{2}$  \n",
    "两边求导：$f'(x_1) = f'(x_0) + (x_1 - x_0) {f''(x_0)}$  \n",
    "令$f'(x_1) = 0$  \n",
    "解方程，得到：$x_1 = x_0 - \\large\\frac{f'(x_0)}{f''(x_0)}$    \n",
    "不断迭代，得到：$x_{n+1} = x_n - \\large\\frac{f'(x_n)}{f''(x_n)}$    \n",
    "上式就是牛顿法的更新公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵除法\n",
    "$AA^{-1} = E$  \n",
    "$A左除B = A^{-1}B$  \n",
    "$B右除A = BA^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.matrix([2, 1, 4, -3]).reshape(2,2)\n",
    "print(\"Matrix A is:\\n\", a, \"\\n\")\n",
    "print(\"Matrix A's inverse matrix is:\\n\", a.I, \"\\n\")\n",
    "print(\"Matrix A product its inverse matrix is:\\n\", a * a.I, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.matrix([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b * a.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.I * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用牛顿法求解最小二乘问题\n",
    "X为$m \\times n$的矩阵，Y为$m \\times 1$的矩阵，W为$n \\times 1$的矩阵  \n",
    "  \n",
    "1.优化函数  \n",
    "线性函数： $Y = XW = [\\sum_{j}^{n}w_{j}x_{1j},\\sum_{j}^{n}w_{j}x_{2j},...,\\sum_{j}^{n}w_{j}x_{mj}]^T$  \n",
    "误差函数： $ERR = \\hat{Y} - Y$  \n",
    "损失函数： $L = \\large\\frac{1}{m}\\normalsize\\sum_{i}^{m}err_{i}^2$  \n",
    "为了求导方便，等价于： $L = \\large\\frac{1}{2}\\normalsize\\sum_{i}^{m}err_{i}^2$\n",
    "  \n",
    "2.一阶导数  \n",
    "对$w_1, w_2...w_n$分别求偏导得到$n \\times 1$矩阵：  \n",
    "$[\\large\\frac{\\partial L}{\\partial w_1}, \\frac{\\partial L}{\\partial w_2},...,\\frac{\\partial L}{\\partial w_n}]$  \n",
    "  \n",
    "向量中的第a个元素等于：$\\large\\frac{\\partial L}{\\partial w_a} \\normalsize = \\sum_{i}^{m}err_{i}x_{ia}\n",
    "= \\sum_{i}^{m}(\\hat{y_i} - y_i)x_{ia}$  \n",
    "  \n",
    "所以向量等于：\n",
    "$[\\sum_{i}^{m}err_{i}x_{i1}, \\sum_{i}^{m}err_{i}x_{i2},...,\\sum_{i}^{m}err_{i}x_{in}]\n",
    "= X^T \\times ERR = X^T \\times (\\hat{Y} - Y) = X^T \\times (XW - Y)$\n",
    "    \n",
    "3.二阶导数  \n",
    "对上述向量的元素分别求偏导得到$n \\times n$阶方阵：  \n",
    "$\n",
    "  \\begin{matrix}\n",
    "   \\large\\frac{\\partial^2 L}{\\partial^2 w_1} & \\large\\frac{\\partial^2 L}{\\partial w_1\\partial w_2} & ... & \\large\\frac{\\partial^2 L}{\\partial w_1\\partial w_n} \\\\\n",
    "   \\large\\frac{\\partial^2 L}{\\partial w_2\\partial w_1} & \\large\\frac{\\partial^2 L}{\\partial w_2\\partial w_2} & ... & \\large\\frac{\\partial^2 L}{\\partial w_2\\partial w_n} \\\\\n",
    "   ... & ... & ... & ...\\\\\n",
    "   \\large\\frac{\\partial^2 L}{\\partial w_n\\partial w_1} & \\large\\frac{\\partial^2 L}{\\partial w_n\\partial w_2} & ... & \\large\\frac{\\partial^2 L}{\\partial^2 w_n} \\\\\n",
    "  \\end{matrix} \\\n",
    "$\n",
    "\n",
    "这个方阵也被称为黑塞矩阵（Hessian Matrix），又译作海森矩阵、海瑟矩阵、海塞矩阵等  \n",
    "矩阵中的第(a, b)个元素等于： \n",
    "$\\large\\frac{\\partial^2 L}{\\partial w_a \\partial w_b} \\normalsize\n",
    "= \\large\\frac{\\partial{\\sum_{i}^{m}(\\sum_{j}^{n}w_{j}x_{ij} - y_{i})x_{ia}}}{\\partial w_b} \n",
    "\\normalsize = \\sum_{i}^{m}x_{ia}x_{ib}$  \n",
    "  \n",
    "所以矩阵H等于：  \n",
    "$\n",
    "  \\begin{matrix}\n",
    "   \\sum_{i}^{m}x_{i1}x_{i1} & \\sum_{i}^{m}x_{i1}x_{i2} & ... & \\sum_{i}^{m}x_{i1}x_{in} \\\\\n",
    "   \\sum_{i}^{m}x_{i2}x_{i1} & \\sum_{i}^{m}x_{i2}x_{i2} & ... & \\sum_{i}^{m}x_{i2}x_{in} \\\\\n",
    "   ... & ... & ... & ... \\\\\n",
    "   \\sum_{i}^{m}x_{in}x_{i1} & \\sum_{i}^{m}x_{in}x_{i2} & ... & \\sum_{i}^{m}x_{in}x_{in} \\\\\n",
    "  \\end{matrix}\n",
    "$  \n",
    "  \n",
    "$ = X^T X$  \n",
    "  \n",
    "4.迭代公式  \n",
    "$W_{new} = W - \\large\\frac{f(W)}{f'(W)}\\normalsize= W - (X^T X)^{-1} \\times X^T(XW - Y)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(x, y):\n",
    "    x = np.matrix(add_bias(x))\n",
    "    m, n = x.shape\n",
    "    y = np.matrix(y).reshape(m, 1)\n",
    "    weights = np.matrix(np.random.normal(0, 0.01, n)).reshape(n, 1)\n",
    "    return weights - (x.T * x).I * x.T * (x * weights - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newton_method(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ 0.00854145  0.00854145]\n",
    " [ 0.99778269  0.99778269]\n",
    " [ 1.9946594   1.9946594 ]\n",
    " [ 3.00730595  3.00730595]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 牛顿法一步求解最小二乘 \n",
    "$W_{new} = W - \\large\\frac{f(W)}{f'(W)}$  \n",
    "\n",
    "$\\normalsize= W - (X^T X)^{-1} \\times X^T(XW - Y)$  \n",
    "\n",
    "$= W - (X^T X)^{-1} \\times X^TXW + (X^T X)^{-1} \\times X^TY$  \n",
    "\n",
    "$= W - W + (X^T X)^{-1}X^TY$  \n",
    "\n",
    "$= (X^T X)^{-1}X^TY$  \n",
    "  \n",
    "化简后的结果与最小二乘法的最优解相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用牛顿法求解根号2的近似值 \n",
    "目标函数$f(x)$，要求目标函数的最小值，那么$f'(x) = 0$\n",
    "\n",
    "\n",
    "令$f'(x) = x ^ 2 - 2$\n",
    "\n",
    "则$f''(x) = 2x$\n",
    "\n",
    "$x_{n+1} = x_n - \\large\\frac{f'(x_n)}{f''(x_n)} = x_n - \\large\\frac{x_n^2-2}{2 x_n} = \\large\\frac{x_n^2+2}{2 x_n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_root(n=2, lr=0.001, threhold=0.0001):\n",
    "    x = n\n",
    "    while abs(x ** 2 - 2) > threhold:\n",
    "        x = (x**2 + 2) / (2 * x)\n",
    "        print(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = square_root(n=2, lr=0.001, threhold=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.4142135623746899 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2 ** 0.5 - test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
